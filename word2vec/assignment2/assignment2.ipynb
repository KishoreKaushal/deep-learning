{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uAkYlLVv-olC"
   },
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cR-qGVUn-vp_"
   },
   "source": [
    "#### 20-newgroup dataset is a collection of newsgroups in 20 topics. Fetch 20-newsgroup dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kaushal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "V8b6X4t-97On",
    "outputId": "0ce4bf1c-15e7-46bd-9cc8-cce7ab38648a"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "bunch = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-auZJMdN_I7J"
   },
   "source": [
    "#### Pre-process the dataset: Convert to lowercase, remove punctuations, symbols, and stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('[a-zA-Z][a-zA-Z]+')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "token_corp = []\n",
    "data = []\n",
    "for d in bunch.data:\n",
    "    tokens = tokenizer.tokenize(d)\n",
    "    tokens = [word.lower() for word in tokens if word not in stop_words]\n",
    "    token_corp.append(tokens)\n",
    "    data.append(\" \".join(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from lerxst wam umd edu thing subject what car nntp posting host rac wam umd edu organization university maryland college park lines wondering anyone could enlighten car saw day it door sports car looked late early it called bricklin the doors really small in addition front bumper separate rest body this know if anyone tellme model name engine specs years production car made history whatever info funky looking car please mail thanks il brought neighborhood lerxst\n",
      "['from', 'lerxst', 'wam', 'umd', 'edu', 'thing', 'subject', 'what', 'car', 'nntp', 'posting', 'host', 'rac', 'wam', 'umd', 'edu', 'organization', 'university', 'maryland', 'college', 'park', 'lines', 'wondering', 'anyone', 'could', 'enlighten', 'car', 'saw', 'day', 'it', 'door', 'sports', 'car', 'looked', 'late', 'early', 'it', 'called', 'bricklin', 'the', 'doors', 'really', 'small', 'in', 'addition', 'front', 'bumper', 'separate', 'rest', 'body', 'this', 'know', 'if', 'anyone', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'production', 'car', 'made', 'history', 'whatever', 'info', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'neighborhood', 'lerxst']\n"
     ]
    }
   ],
   "source": [
    "print(data[0])\n",
    "# corpus\n",
    "print(token_corp[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the words in the dataset to vectors of dimension 100 using Word2Vec. Ignore words whose frequency is less than 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(token_corp, min_count=10, size = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 18159\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary Size: {}\".format(len(model.wv.vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the most similar words in the corpus to the word “car” along with their similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cars', 0.8846904635429382)\n",
      "('tires', 0.8513389825820923)\n",
      "('bike', 0.8468177318572998)\n",
      "('truck', 0.8303914666175842)\n",
      "('dealer', 0.8256232738494873)\n",
      "('owner', 0.8205631375312805)\n",
      "('bikes', 0.809188961982727)\n",
      "('honda', 0.8055466413497925)\n",
      "('bought', 0.8047472834587097)\n",
      "('toyota', 0.8018370866775513)\n"
     ]
    }
   ],
   "source": [
    "print(*model.wv.most_similar('car'), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find top 5 words similar to the following operations:\n",
    "\n",
    "* girl + father - boy\n",
    "* sports - bat + ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('son', 0.8516300916671753)\n",
      "('mother', 0.843051016330719)\n",
      "('miracles', 0.8179592490196228)\n",
      "('spirit', 0.8175290822982788)\n",
      "('empty', 0.8152676224708557)\n",
      "('sister', 0.8142035603523254)\n",
      "('holy', 0.8112156391143799)\n",
      "('risen', 0.8057224154472351)\n",
      "('believed', 0.802990198135376)\n",
      "('his', 0.8017452955245972)\n"
     ]
    }
   ],
   "source": [
    "print(*model.wv.most_similar(positive=['girl', 'father'], negative=['boy']), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tonight', 0.8668610453605652)\n",
      "('morning', 0.8158824443817139)\n",
      "('sharks', 0.8068385124206543)\n",
      "('night', 0.7935193181037903)\n",
      "('playoffs', 0.7929466962814331)\n",
      "('league', 0.7889211177825928)\n",
      "('quebec', 0.7885714769363403)\n",
      "('saturday', 0.7876542806625366)\n",
      "('sunday', 0.786758303642273)\n",
      "('played', 0.780249297618866)\n"
     ]
    }
   ],
   "source": [
    "print(*model.wv.most_similar(positive=['sports', 'ball'], negative=['bat']), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "word2vec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
